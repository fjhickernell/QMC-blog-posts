\begin{comment}
\title{parslTestbookQMCblog}
\author{Joshua Jay Herman (QMC Development Team),  Brandon Sharp, and Sou-Cheng Choi (Illinois Tech and SouLab LLC)}
\date{September 2025}

\maketitle
Accelerating QMCpy Notebook Tests with Parsl
\end{comment}

\subsection{Introduction}

Notebook regression testing \scnote{is it regression testing or unit testing?} ensures that interactive examples and analyses
remain correct and reproducible, catching regressions introduced by changes in
code, dependencies, or execution environments. For QMCPy \cite{QMCPy2020a}, this
process is both massively parallel and resource-intensive due to the number and
complexity of its notebooks.

This blog post summarizes our work on accelerating notebook regression testing
(using Testbook-based tests, which can be viewed as notebook-level unit tests)
as presented in our ParslFest 2025 talk \cite{parslfest2025}, and outlines
directions for further development.

The slides accompanying the presentation are available at:
\href{https://github.com/QMCSoftware/QMCSoftware/raw/refs/heads/parsl_presentation/demos/talk_paper_demos/Parslfest_2025/Parsl%20Testbook%20Speedup.pptx}{Parsl Testbook Speedup}.
\scnote{Link broken.}

\subsection{Methodology}

Our choice to adopt Testbook \cite{testbook2021} is motivated by its ability to
execute Jupyter notebooks directly within a test environment, enabling
fine-grained validation of both code cells and notebook state. Testbook also
integrates cleanly with our existing testing directory structure, where other
unit tests are organized without requiring full notebook execution. This
preserves modularity, simplifies debugging, and avoids unnecessary duplication
of logic.

To support scalable notebook testing, we developed a lightweight yet flexible
test harness that enables Parsl \cite{parsl2019} to orchestrate Testbook-based
unit tests. By treating each notebook test as an independent Parsl app, the
harness realizes an embarrassingly parallel workflow suitable for local
multiprocessing, HPC schedulers, or cloud environments.

The harness coordinates three primary components to achieve reproducible,
high-throughput notebook testing:

\begin{itemize}
    \item \textbf{Continuous Integration (CI):} A GitHub Actions workflow
    prepares the execution environment (Conda environment creation, minimal
    \LaTeX{} installation, optional swap configuration), installs project
    dependencies, and triggers the appropriate test targets (e.g.,
    \texttt{make booktests\_parallel\_no\_docker}). This ensures consistent,
    version-controlled execution across platforms.

    \item \textbf{Parsl controller and workers:} Parsl provisions local or
    remote executors---processes, threads, or cluster jobs---and schedules
    notebook tests as independent tasks. This enables parallel execution with
    configurable concurrency limits, resource profiles, and executor backends.

    \item \textbf{Testbook runner and artifact collection:} Each worker
    executes its assigned notebook tests through Testbook. Outputs, execution
    logs, error traces, generated figures, and notebook artifacts with executed
    cells are returned to the Parsl controller and uploaded by CI for
    inspection, provenance tracking, and debugging.
\end{itemize}

Key features of the harness include pinned Conda environment specifications for
reproducibility, customizable Parsl executors (local, HPC, or cloud), timeout
and retry policies for handling flaky or long-running tests, and centralized
logging to streamline diagnosis of failures. Together, these components provide
a robust framework for scalable, automated validation of computational
notebooks.


\subsection{Results}

To determine a baseline speedup with a subset of notebooks, we observed a speedup. 
After expanding our test coverage to search for syntax errors in additional notebooks, we now see a 3.0-fold speedup, which is consistent with our expectations, as illustrated in Figure~\ref{fig:parsl_speedup}. 

\begin{figure}[htbp]
    \centering
    \includegraphics[width=1\textwidth]{booktests/parsl_speedup.png}
    \caption{Parallel testing speedup using Parsl with 4 workers (processors) against sequential execution of tests.}
    \label{fig:parsl_speedup}
\end{figure}


This was tested on a Linux system running on an AMD64 architecture with 16 CPU cores. If you want to run the tests we have made for QMCPy, you can run 'make testbook'

\subsection{Further Work}

Due to the above results, this indicates that we should extend our testing to doctest and `pytest` in Parsl.

Now, because many people have multicore processors, we can increase individual productivity so that our tests can demonstrate that no regressions have been introduced.

Furthermore, regarding feedback on the presentation to the ParslFest participants, the system is quite general. This suggests a distributed test system could benefit Parsl users by enabling them to distribute their own test workloads.

Finally, we could expand our work to encompass Python doctests, as well as unit testing using pytest or unittest, in addition to testing Jupyter notebooks.